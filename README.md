# Customer Churn Prediction Platform

A selfâ€‘contained, endâ€‘toâ€‘end example showing how to build, train, and deploy a churn prediction model using Delta Lake, PySpark, TensorFlow, XGBoost, and FastAPI. It includes scripts to generate synthetic data, run local ingestion & preprocessing, train an LSTM+XGBoost ensemble, and expose a REST API in Docker.

---

## ğŸš€ Features

- **Data Ingestion**: Load CSV into Delta Lake (local) via `src/ingest.py`.
- **Preprocessing**: Engineer features, pivot events, and split into train/test with `src/preprocess.py`.
- **Data Generation**: Create 1,000-row synthetic dataset via `src/generate_data.py`.
- **Modeling**: Train an LSTM + XGBoost ensemble and save models in `models/` using `src/train_model.py`.
- **API**: FastAPI service (`src/app.py`) with `/predict` endpoint for inference.
- **Containerization**: Dockerfile + `run_docker.sh` to build and run your API anywhere.
- **Helper Scripts**: `scripts/predict.sh` to test predictions easily.

---

## ğŸ“‹ Prerequisites

- macOS or Linux with:
  - PythonÂ 3.10+ and `venv`
  - Docker
  - JavaÂ 11 runtime (for Spark)

---

## ğŸ› ï¸ Setup & Quickstart

1. **Clone the repo**

   ```bash
   git clone git@github.com:<your-username>/churn-prediction-dev.git
   cd churn-prediction-dev
   ```

2. **Create a virtual environment & install dependencies**

   ```bash
   python3 -m venv churn-dev
   source churn-dev/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

3. **Generate sample data**

   ```bash
   python src/generate_data.py
   ```

4. **Ingest into Delta Lake**

   ```bash
   python src/ingest.py
   ```

5. **Preprocess & split**

   ```bash
   python src/preprocess.py
   ```

6. **Train & save models**

   ```bash
   python src/train_model.py
   ```

7. **Run API locally**

   ```bash
   uvicorn src.app:app --reload --port 8000
   ```

8. **Test endpoint**

   ```bash
   ./scripts/predict.sh
   ```

9. **Dockerize & run**

   ```bash
   ./run_docker.sh
   ```

---

## ğŸ“‚ Repository Structure

```plaintext
churn-prediction-dev/
â”œâ”€â”€ src/                 # PySpark, model, and API code
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ generate_data.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ data/                # sample CSV or generator script
â”œâ”€â”€ models/              # saved LSTM & XGBoost models (gitignored)
â”œâ”€â”€ scripts/             # helper bash scripts
â”‚   â”œâ”€â”€ predict.sh
â”œâ”€â”€ Dockerfile           # container definition
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ run_docker.sh        # helper Docker script
â”œâ”€â”€ predict.sh   # helper API test script
â””â”€â”€ run_docker.sh
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“ Next Steps

- Push Docker image to Docker Hub or ECR
- Automate CI/CD (GitHub Actions, GitLab CI)
- Deploy to AWS ECS/Fargate with API Gateway
- Add monitoring & logging (Prometheus, Grafana)
